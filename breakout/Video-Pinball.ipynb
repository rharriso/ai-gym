{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from progressbar import ProgressBar\n",
    "from time import sleep\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import scipy\n",
    "from matplotlib import image\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Flatten\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(action_size, alpha, initializer='glorot_uniform'):\n",
    "    optimizer = optimizers.RMSprop(lr=alpha)\n",
    "    \n",
    "    net = Sequential([\n",
    "        Conv2D(\n",
    "            32,\n",
    "            (8, 8),\n",
    "            strides=(4,4),\n",
    "            input_shape=(84, 84, 4),\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer,\n",
    "            data_format=\"channels_last\"\n",
    "        ),\n",
    "        Conv2D(\n",
    "            64,\n",
    "            (4,4),\n",
    "            strides=(2,2),\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer\n",
    "        ),\n",
    "        Conv2D(\n",
    "            64,\n",
    "            (3,3),\n",
    "            strides=(1,1),\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer\n",
    "        ),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu', kernel_initializer=initializer),\n",
    "        Dense(action_size, activation='linear', kernel_initializer=initializer)\n",
    "    ])\n",
    "    net.compile(loss='mse', optimizer=optimizer)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_frame(frame, prev_frame):\n",
    "    r = frame[:,:,0] # red channel\n",
    "    g = frame[:,:,1] # blue channel\n",
    "    b = frame[:,:,2] # green channel\n",
    "    l = (0.2126*r + 0.7152*g + 0.0722*b) # luminescence \n",
    "    max_r = max(np.max(prev_frame[:,:,0]), np.max(r))\n",
    "    max_g = max(np.max(prev_frame[:,:,1]), np.max(g))\n",
    "    max_b = max(np.max(prev_frame[:,:,2]), np.max(b))\n",
    "    \n",
    "    \n",
    "    normalized_color = np.zeros((frame.shape[0], frame.shape[1], 4))\n",
    "    normalized_color[:,:,0] = r.astype(np.float64) / max_r\n",
    "    normalized_color[:,:,1] = g.astype(np.float64) / max_g\n",
    "    normalized_color[:,:,2] = b.astype(np.float64) / max_b\n",
    "    normalized_color[:,:,3] = l\n",
    "    \n",
    "    \n",
    "    phi_frame = np.zeros((84, 84, 4))\n",
    "    zoom_shape = np.array(phi_frame.shape, dtype=float) / np.array(normalized_color.shape, dtype=float)\n",
    "    phi_frame = scipy.ndimage.zoom(normalized_color, zoom_shape)\n",
    "    return phi_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 180.00 483.00\" width=\"180pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 176,-479 176,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140063895479968 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140063895479968</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 172,-474.5 172,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-452.8\">conv2d_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140075190608952 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140075190608952</title>\n",
       "<polygon fill=\"none\" points=\"24.5,-365.5 24.5,-401.5 147.5,-401.5 147.5,-365.5 24.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-379.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140063895479968&#45;&gt;140075190608952 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140063895479968-&gt;140075190608952</title>\n",
       "<path d=\"M86,-438.313C86,-430.289 86,-420.547 86,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"89.5001,-411.529 86,-401.529 82.5001,-411.529 89.5001,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140075190677288 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140075190677288</title>\n",
       "<polygon fill=\"none\" points=\"24.5,-292.5 24.5,-328.5 147.5,-328.5 147.5,-292.5 24.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-306.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140075190608952&#45;&gt;140075190677288 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140075190608952-&gt;140075190677288</title>\n",
       "<path d=\"M86,-365.313C86,-357.289 86,-347.547 86,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"89.5001,-338.529 86,-328.529 82.5001,-338.529 89.5001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140075190751976 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140075190751976</title>\n",
       "<polygon fill=\"none\" points=\"24.5,-219.5 24.5,-255.5 147.5,-255.5 147.5,-219.5 24.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-233.8\">conv2d_3: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140075190677288&#45;&gt;140075190751976 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140075190677288-&gt;140075190751976</title>\n",
       "<path d=\"M86,-292.313C86,-284.289 86,-274.547 86,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"89.5001,-265.529 86,-255.529 82.5001,-265.529 89.5001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140075190754328 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140075190754328</title>\n",
       "<polygon fill=\"none\" points=\"31,-146.5 31,-182.5 141,-182.5 141,-146.5 31,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-160.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140075190751976&#45;&gt;140075190754328 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140075190751976-&gt;140075190754328</title>\n",
       "<path d=\"M86,-219.313C86,-211.289 86,-201.547 86,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"89.5001,-192.529 86,-182.529 82.5001,-192.529 89.5001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140075190755280 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140075190755280</title>\n",
       "<polygon fill=\"none\" points=\"35,-73.5 35,-109.5 137,-109.5 137,-73.5 35,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-87.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140075190754328&#45;&gt;140075190755280 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140075190754328-&gt;140075190755280</title>\n",
       "<path d=\"M86,-146.313C86,-138.289 86,-128.547 86,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"89.5001,-119.529 86,-109.529 82.5001,-119.529 89.5001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140063895479464 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140063895479464</title>\n",
       "<polygon fill=\"none\" points=\"35,-0.5 35,-36.5 137,-36.5 137,-0.5 35,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140075190755280&#45;&gt;140063895479464 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140075190755280-&gt;140063895479464</title>\n",
       "<path d=\"M86,-73.3129C86,-65.2895 86,-55.5475 86,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"89.5001,-46.5288 86,-36.5288 82.5001,-46.5289 89.5001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.00025\n",
    "gamma=0.99\n",
    "epochs=5000\n",
    "action_update_interval = 4\n",
    "q_update_interval = 16\n",
    "qhat_update_interval = 500\n",
    "sample_size=32 # how many samples do we take each time\n",
    "min_replay_size = 500 # whhen does training start (replay mem size)\n",
    "max_replay_size = 25000 # what is the max replay memory\n",
    "chart_interval = 1000\n",
    "\n",
    "# step increment at begining of loop\n",
    "step = -1\n",
    "\n",
    "# trainy boi\n",
    "training_started = False\n",
    "frame_memory = np.zeros((max_replay_size, 84, 84, 4), dtype='float')\n",
    "prime_frame_memory = np.zeros((max_replay_size, 84, 84, 4), dtype='float')\n",
    "action_memory = np.zeros((max_replay_size, 1), dtype='int')\n",
    "reward_memory = np.zeros((max_replay_size, 1), dtype='float')\n",
    "done_memory = np.zeros((max_replay_size, 1), dtype='bool')\n",
    "\n",
    "replay_index = -1\n",
    "\n",
    "# stats\n",
    "training_rewards = []\n",
    "rewards = []\n",
    "mean_rewards = []\n",
    "mean_training_rewards = []\n",
    "epsilons = []\n",
    "\n",
    "# init env\n",
    "env_name = 'VideoPinball-v0'\n",
    "env = gym.make(env_name)\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.env.action_space.n\n",
    "\n",
    "# init networks\n",
    "q_net = create_network(action_size, alpha)\n",
    "q_hat_net = create_network(action_size, alpha, 'zeros')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "training_score = []\n",
    "test_score = []\n",
    "last_episode = 0\n",
    "\n",
    "SVG(model_to_dot(q_net).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def time_usage(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        beg_ts = time.time()\n",
    "        retval = func(*args, **kwargs)\n",
    "        end_ts = time.time()\n",
    "        # print(\"elapsed time %s: %f\" % (func.__name__, end_ts - beg_ts))\n",
    "        return retval\n",
    "    return wrapper\n",
    "\n",
    "def run_episode(epsilon, pool_actions=False, render=True):\n",
    "    # print(\"Start Episode: epsilon %s\", epsilon)\n",
    "    moves = 0\n",
    "    beg_ts = time.time()\n",
    "    done = False\n",
    "    frame = env.reset()\n",
    "    prev_frame = np.zeros_like(frame) # the \"prevvious\" frame is nothing\n",
    "    phi_frame = pre_process_frame(frame, prev_frame)\n",
    "\n",
    "    while not done and moves < 1000:\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.randint(action_size)\n",
    "        else:\n",
    "            phi_shape = phi_frame.shape\n",
    "            shaped_frame = phi_frame.reshape(1, phi_shape[0], phi_shape[1], phi_shape[2])\n",
    "            action = np.argmax(q_net.predict(shaped_frame))\n",
    "\n",
    "        prime_frame, reward, done, ale_lives = env.step(action)\n",
    "        phi_prime_frame = pre_process_frame(frame, prime_frame)\n",
    "        lives = ale_lives['ale.lives']\n",
    "        done = done or lives == 0\n",
    "\n",
    "        if render:\n",
    "            env.render()\n",
    "            sleep(0.0001)\n",
    "\n",
    "        yield phi_frame, action, reward, phi_prime_frame, done, lives\n",
    "\n",
    "        phi_frame = phi_prime_frame\n",
    "        prev_frame = frame\n",
    "        frame = prime_frame\n",
    "        moves += 1\n",
    "\n",
    "    end_ts = time.time()\n",
    "    # print(\"elapsed time run_episode: %s moves %fs\" % (moves, end_ts - beg_ts))\n",
    "\n",
    "weight_updates = 0\n",
    "\n",
    "# @time_usage\n",
    "def update_weights():\n",
    "    # crop memory\n",
    "    global frame_memory, action_memory, reward_memory, prime_frame_memory, done_memory, weight_updates, replay_index\n",
    "\n",
    "    memory_sample = random.sample(\n",
    "        range(0, min(replay_index, max_replay_size)),\n",
    "        sample_size\n",
    "    )\n",
    "\n",
    "    _frame_batch = frame_memory[memory_sample]\n",
    "    _prime_frame_batch = prime_frame_memory[memory_sample]\n",
    "    _action_batch = action_memory[memory_sample]\n",
    "    _reward_batch = reward_memory[memory_sample]\n",
    "    _done_batch = done_memory[memory_sample]\n",
    "\n",
    "    _predictions = q_net.predict(_frame_batch)\n",
    "    _corrections = _predictions.copy()\n",
    "    _prime_predictions = q_hat_net.predict(_prime_frame_batch)\n",
    "\n",
    "    for i in range(0, sample_size):\n",
    "        _done = _done_batch[i]\n",
    "        _reward = _reward_batch[i]\n",
    "        _action = _action_batch[i]\n",
    "\n",
    "        _prime_prediction = _prime_predictions[i]\n",
    "        if _done:\n",
    "            _corrections[i, _action] = _reward_batch[i]\n",
    "        else:\n",
    "            _corrections[i, _action] = _reward + gamma * np.max(_prime_prediction)\n",
    "    q_net.train_on_batch(_frame_batch, _corrections)\n",
    "\n",
    "\n",
    "    if weight_updates % qhat_update_interval == 0:\n",
    "        # print(\"updating target\")\n",
    "        q_hat_net.set_weights(q_net.get_weights())\n",
    "    weight_updates += 1\n",
    "\n",
    "step = -1\n",
    "training_started = False\n",
    "\n",
    "# for episode in pbar(range(last_episode, epochs)):\n",
    "if True:\n",
    "    last_episode = episode\n",
    "    \n",
    "    if episode < epochs / 10:\n",
    "        epsilon = 0.99\n",
    "    elif episode < epochs / 4:\n",
    "        epsilon = 0.75\n",
    "    elif episode < epochs / 2:\n",
    "        epsilon = 0.50\n",
    "    elif episode < 3 * epochs / 4:\n",
    "        epsilon = 0.25\n",
    "    else:\n",
    "        epsilon = 0.01\n",
    "\n",
    "    training_score = 0\n",
    "\n",
    "    # for every action in the episode\n",
    "    for (\n",
    "        frame,\n",
    "        action,\n",
    "        reward,\n",
    "        prime_frame,\n",
    "        done,\n",
    "        lives\n",
    "    ) in run_episode(.99, pool_actions=True, render=True):\n",
    "        step += 1\n",
    "        #\n",
    "        replay_index += 1\n",
    "        replay_array_index = replay_index % max_replay_size\n",
    "        frame_memory[replay_array_index] = frame\n",
    "        prime_frame_memory[replay_array_index] = prime_frame\n",
    "        action_memory[replay_array_index] = action\n",
    "        reward_memory[replay_array_index] = reward\n",
    "        done_memory[replay_array_index] = done\n",
    "\n",
    "        training_score += reward\n",
    "\n",
    "        # if time do the training\n",
    "        if step % q_update_interval == 0 and min_replay_size < replay_index:\n",
    "            if not training_started:\n",
    "                training_started = True\n",
    "                # print(\"Training Started: \", step)\n",
    "            update_weights()\n",
    "\n",
    "\n",
    "# #     test the net\n",
    "#     test_score = 0\n",
    "\n",
    "#     for (\n",
    "#         prev_frame,\n",
    "#         action,\n",
    "#         reward,\n",
    "#         frame,\n",
    "#         done,\n",
    "#         lives\n",
    "#     ) in run_episode(0.01, pool_actions=False, render=True):\n",
    "#         test_score += test_score\n",
    "\n",
    "    # print(\"Record metrics\")\n",
    "    training_rewards.append(training_score)\n",
    "#     rewards.append(test_score)\n",
    "#     mean_rewards.append(np.mean(rewards[-100:]))\n",
    "    mean_training_rewards.append(np.mean(training_rewards[-100:]))\n",
    "    epsilons.append(epsilon)\n",
    "\n",
    "    # display progress\n",
    "    if True: #(episode + 1) % chart_interval == 0:\n",
    "        index_step = 10\n",
    "        episodes_num = np.arange(0, len(mean_training_rewards))[0::index_step]\n",
    "        _mean_training_rewards = mean_training_rewards[0::index_step]\n",
    "#         _mean_rewards = mean_rewards[0::index_step]\n",
    "#         _rewards = rewards[0::index_step]\n",
    "        _training_rewards = training_rewards[0::index_step]\n",
    "        _epsilons = epsilons[0::index_step]\n",
    "        episode_index = len(mean_training_rewards)\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 5), dpi=100)\n",
    "        par1 = fig.subplots()\n",
    "        par2 = par1.twinx()\n",
    "\n",
    "        par2.plot(episodes_num, _epsilons, marker='o', markersize=5, label='Epsilon', color='purple')\n",
    "        par2.set_ylim(-0.1, 1.1)\n",
    "        par2.legend(loc='lower right')\n",
    "\n",
    "        par1.plot(episodes_num, _training_rewards, marker='o', markersize=5, label='Training Reward')\n",
    "#         par1.plot(episodes_num, _rewards, marker='o', markersize=5, label='Test Reward')\n",
    "        par1.plot(episodes_num, _mean_training_rewards, marker='x', markersize=5, label='Mean Training Rewards')\n",
    "#         par1.plot(episodes_num, _mean_rewards, marker='o', markersize=5, label='Mean Test Reward')\n",
    "        par1.legend(loc='lower left')\n",
    "        par1.set_xlabel('epoch')\n",
    "        par1.set_ylabel('Mean Reward')\n",
    "        plt.pause(0.01)\n",
    "\n",
    "        # save after charting\n",
    "        model_file = '%s-%s-%s.weights' % (env_name, alpha, episode)\n",
    "        q_net.save_weights(model_file)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '%s-%s-%s.weights' % (env_name, alpha, episode)\n",
    "net.save_weights(model_file)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(q_net).create(prog=\"dot\", format=\"svg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
